{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWAt7dKALpc0PfBaE5RR4a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/williamsueyoshi/unicamp_feec_ia368_120282/blob/main/exercicio_selecao_120282.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports de bibliotecas"
      ],
      "metadata": {
        "id": "9DC6desfOvsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import nltk\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGB6Xo9QOviq",
        "outputId": "6d454d46-a98d-4984-c1b0-4eb909fc32f0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import e tratamento da CISI Collection"
      ],
      "metadata": {
        "id": "lTW43H0w2NTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd '/content'"
      ],
      "metadata": {
        "id": "9QlfpEHtT_7K"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BBtLnq_5Q5bN"
      },
      "outputs": [],
      "source": [
        "!tar xf \"/content/cisi.tar.gz\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trata arquivo CISI.ALL (contém os documentos a serem pesquisados)\n",
        "\n",
        "with open('/content/CISI.ALL', 'r') as f:\n",
        "    input_completo = f.read()\n",
        "\n",
        "# Lista com documentos separados e ID no formato certo para tratamento\n",
        "docs = ['\\n.I\\n' + i for i in input_completo.split('.I ')[1:]]\n",
        "\n",
        "# Legenda dos campos do arquivo (metadados)\n",
        "metadata_dict = {\n",
        "    '.I': 'ID',\n",
        "    '.T': 'Titulo',\n",
        "    '.A': 'Autor',\n",
        "    '.B': 'Referencia',\n",
        "    '.W': 'Texto',\n",
        "    '.X': 'Referencia Cruzada',\n",
        "    }\n",
        "\n",
        "# String com simbolo dos campos para separação no dicionário\n",
        "metadata_simbolos_str = ''\n",
        "for simbolo in metadata_dict.keys():\n",
        "    metadata_simbolos_str += ('\\n' + simbolo + '|')\n",
        "metada_simbolo_str = metadata_simbolos_str[:-1]\n",
        "\n",
        "# Cria dicionário com ID dos documentos na chave\n",
        "docs_dict = {}\n",
        "for doc in docs:\n",
        "\n",
        "    # Separa string do documento completo nos campos dos metadados\n",
        "    doc_dict = {}\n",
        "    for simbolo_campo, nome_campo in metadata_dict.items():\n",
        "        if ('\\n' + simbolo_campo) in doc:\n",
        "            texto_campo = doc.split('\\n' + simbolo_campo, 1)[1]\n",
        "            texto_campo = re.split(metada_simbolo_str, texto_campo)[0]\n",
        "            texto_campo = texto_campo.replace('\\n', ' ').strip()\n",
        "            doc_dict[nome_campo] = texto_campo\n",
        "\n",
        "    docs_dict[int(doc_dict['ID'])] = doc_dict"
      ],
      "metadata": {
        "id": "vrXsGaS2Db-X"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trata arquivo CISI.QRY (contém queries a serem executadas)\n",
        "\n",
        "with open('/content/CISI.QRY', 'r') as f:\n",
        "    input_completo = f.read()\n",
        "\n",
        "# Lista com queries separadas e ID no formato certo para tratamento\n",
        "qrys = ['\\n.I\\n' + i for i in input_completo.split('.I ')[1:]]\n",
        "\n",
        "# Legenda dos campos do arquivo (metadados)\n",
        "metadata_dict = {\n",
        "    '.I': 'ID',\n",
        "    '.T': 'Titulo',\n",
        "    '.A': 'Autor',\n",
        "    '.B': 'Referencia',\n",
        "    '.W': 'Texto',\n",
        "    }\n",
        "\n",
        "# String com simbolo dos campos para separação no dicionário\n",
        "metadata_simbolos_str = ''\n",
        "for simbolo in metadata_dict.keys():\n",
        "    metadata_simbolos_str += ('\\n' + simbolo + '|')\n",
        "metada_simbolo_str = metadata_simbolos_str[:-1]\n",
        "\n",
        "# Cria dicionário com ID das queries na chave\n",
        "qrys_dict = {}\n",
        "for qry in qrys:\n",
        "\n",
        "    # Separa string do documento completo nos campos dos metadados\n",
        "    qry_dict = {}\n",
        "    for simbolo_campo, nome_campo in metadata_dict.items():\n",
        "        if ('\\n' + simbolo_campo) in qry:\n",
        "            texto_campo = qry.split('\\n' + simbolo_campo, 1)[1]\n",
        "            texto_campo = re.split(metada_simbolo_str, texto_campo)[0]\n",
        "            texto_campo = texto_campo.replace('\\n', ' ').strip()\n",
        "            qry_dict[nome_campo] = texto_campo\n",
        "\n",
        "    qrys_dict[int(qry_dict['ID'])] = qry_dict"
      ],
      "metadata": {
        "id": "W-d3Nkk0iWS9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trata arquivo CISI.REL (contém prova real do resultado das queries)\n",
        "\n",
        "with open('/content/CISI.REL', 'r') as f:\n",
        "    input_completo = f.read()\n",
        "\n",
        "# Lista com retorno esperado por ID (um doc_id por linha, repete várias qry_id)\n",
        "rels = input_completo.split('\\n')[:-1]\n",
        "\n",
        "# Cria dicionário com ID das queries na chave\n",
        "rels_dict = {}\n",
        "for rel in rels:\n",
        "\n",
        "    # Atribui cada linha do REL à query ID correspondente\n",
        "    rel = rel.lstrip().split('\\t0')[0]\n",
        "    qry_id = rel.split(' ', 1)[0]\n",
        "    doc_id = rel.split(' ', 1)[1].strip()\n",
        "\n",
        "    if int(qry_id) not in rels_dict:\n",
        "        rels_dict[int(qry_id)] = {\n",
        "            'Query ID': qry_id,\n",
        "            'Doc IDs': [],\n",
        "        }\n",
        "\n",
        "    rels_dict[int(qry_id)]['Doc IDs'].append(doc_id)"
      ],
      "metadata": {
        "id": "Bp_S8Zzhs952"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificação dos dicionários criados, contendo os dados dos arquivos .ALL, .QRY e .REL"
      ],
      "metadata": {
        "id": "ndqflvmQuWBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs_dict[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDrfZXD9u58t",
        "outputId": "95857c28-1c6f-4d0e-e608-42ddc501af87"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ID': '1',\n",
              " 'Titulo': '18 Editions of the Dewey Decimal Classifications',\n",
              " 'Autor': 'Comaromi, J.P.',\n",
              " 'Texto': \"The present study is a history of the DEWEY Decimal Classification.  The first edition of the DDC was published in 1876, the eighteenth edition in 1971, and future editions will continue to appear as needed.  In spite of the DDC's long and healthy life, however, its full story has never been told.  There have been biographies of Dewey that briefly describe his system, but this is the first attempt to provide a detailed history of the work that more than any other has spurred the growth of librarianship in this country and abroad.\",\n",
              " 'Referencia Cruzada': '1\\t5\\t1 92\\t1\\t1 262\\t1\\t1 556\\t1\\t1 1004\\t1\\t1 1024\\t1\\t1 1024\\t1\\t1'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qrys_dict[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAnAVb-Ju56N",
        "outputId": "a078b61f-05c4-49bb-9592-d7d3613272fe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ID': '1',\n",
              " 'Texto': 'What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rels_dict[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzRcR0ktu5xe",
        "outputId": "0ac784ee-ef45-48e2-e810-8ab10291b62e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Query ID': '1',\n",
              " 'Doc IDs': ['28',\n",
              "  '35',\n",
              "  '38',\n",
              "  '42',\n",
              "  '43',\n",
              "  '52',\n",
              "  '65',\n",
              "  '76',\n",
              "  '86',\n",
              "  '150',\n",
              "  '189',\n",
              "  '192',\n",
              "  '193',\n",
              "  '195',\n",
              "  '215',\n",
              "  '269',\n",
              "  '291',\n",
              "  '320',\n",
              "  '429',\n",
              "  '465',\n",
              "  '466',\n",
              "  '482',\n",
              "  '483',\n",
              "  '510',\n",
              "  '524',\n",
              "  '541',\n",
              "  '576',\n",
              "  '582',\n",
              "  '589',\n",
              "  '603',\n",
              "  '650',\n",
              "  '680',\n",
              "  '711',\n",
              "  '722',\n",
              "  '726',\n",
              "  '783',\n",
              "  '813',\n",
              "  '820',\n",
              "  '868',\n",
              "  '869',\n",
              "  '894',\n",
              "  '1162',\n",
              "  '1164',\n",
              "  '1195',\n",
              "  '1196',\n",
              "  '1281']}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funções para execução da busca para cada query"
      ],
      "metadata": {
        "id": "7CicHwQGqsx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para pré-processar o texto do documento\n",
        "def preprocess_text(text):\n",
        "\n",
        "    # Remove a pontuação e transforma tudo em minúsculas\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
        "\n",
        "    # Divide o texto em palavras\n",
        "    words = text.split()\n",
        "\n",
        "    # Remove as stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Realiza a stemming das palavras\n",
        "    stemmer = PorterStemmer()\n",
        "    words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "    # Retorna as palavras pré-processadas como uma lista\n",
        "    return words\n",
        "\n",
        "\n",
        "# Função para calcular o IDF (Inverse Document Frequency) de um termo\n",
        "def calculate_idf(term, doc_dict):\n",
        "\n",
        "    aux = sum(1 for doc_text in doc_dict.values() if term in doc_text)\n",
        "    num_docs_with_term = aux\n",
        "\n",
        "    if num_docs_with_term == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return math.log(len(doc_dict)/num_docs_with_term)\n",
        "\n",
        "\n",
        "# Função para calcular o BM25 score de um documento para uma consulta\n",
        "def calculate_bm25_score(doc_id, query_terms, doc_dict, k1=1.2, b=0.75):\n",
        "\n",
        "    doc_text = doc_dict[doc_id]\n",
        "    doc_len = len(doc_text)\n",
        "\n",
        "    aux = sum(len(doc_text) for doc_text in doc_dict.values()) / len(doc_dict)\n",
        "    avg_doc_len = aux\n",
        "\n",
        "    doc_terms = preprocess_text(doc_text)\n",
        "\n",
        "    query_term_counts = Counter(query_terms)\n",
        "    score = 0\n",
        "    for term in set(query_terms):\n",
        "        if term not in doc_terms:\n",
        "            continue\n",
        "        tf = doc_terms.count(term)\n",
        "        idf = calculate_idf(term, doc_dict)\n",
        "        query_tf = query_term_counts[term]\n",
        "        score += idf * ((k1 + 1)*tf) / (k1*((1 - b) + b*(doc_len/avg_doc_len))\n",
        "                        + tf)*query_tf\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "# Função para classificar todos os documentos da coleção em ordem decrescente\n",
        "#   de BM25 score para uma consulta\n",
        "def rank_documents(query, doc_dict):\n",
        "\n",
        "    query_terms = preprocess_text(query)\n",
        "\n",
        "    doc_scores = {}\n",
        "    for doc_id, doc_text in doc_dict.items():\n",
        "        doc_scores[doc_id] = calculate_bm25_score(doc_id, query_terms,\n",
        "                                                  doc_dict)\n",
        "        sorted_doc_scores = sorted(doc_scores.items(), key=lambda x: x[1],\n",
        "                                   reverse=True)\n",
        "        ranked_docs = [(doc_id, score) for doc_id, score in sorted_doc_scores]\n",
        "\n",
        "    return ranked_docs\n",
        "\n",
        "\n",
        "# Função para executar buscas a partir de dicionários de documentos e queries,\n",
        "#   especificando a quantidade de documentos a serem retornados por query\n",
        "def executa_buscas(docs_dict, qrys_dict, qtd_returns, imprime_log):\n",
        "\n",
        "    qrys_return = {}\n",
        "    for qry_id, qry_text in qrys_dict.items():\n",
        "        \n",
        "        if imprime_log:\n",
        "            print(f'Processando Query {qry_id}\\n')\n",
        "        \n",
        "        doc_scores = rank_documents(qry_text, docs_dict)\n",
        "\n",
        "        qrys_return[qry_id] = []\n",
        "        for doc_id, score in doc_scores[:10]:\n",
        "            qrys_return[qry_id].append(doc_id)\n",
        "            if imprime_log:\n",
        "                print(f'Doc ID: {doc_id}')\n",
        "                print(f'Score: {score:.4f}')\n",
        "                print(f'Text: {docs_dict[doc_id]}')\n",
        "                print('-'*50)\n",
        "        \n",
        "        if imprime_log:\n",
        "            print('')\n",
        "    \n",
        "    return qrys_return"
      ],
      "metadata": {
        "id": "QooI0Z9SQMQP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execução das buscas"
      ],
      "metadata": {
        "id": "EBUgSOK2tpwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforma documentos e queries no formato a ser inserido no código de busca\n",
        "\n",
        "docs_input = {}\n",
        "for doc_id, doc_dict in docs_dict.items():\n",
        "    doc_input = (doc_dict.get('Titulo', '') + ' '\n",
        "                 + doc_dict.get('Autor', '') + ' '\n",
        "                 + doc_dict.get('Referencia', '') + ' '\n",
        "                 + doc_dict.get('Texto', ''))\n",
        "    docs_input[doc_id] = doc_input.strip()\n",
        "\n",
        "qrys_input = {}\n",
        "for qry_id, qry_dict in qrys_dict.items():\n",
        "    qry_input = (qry_dict.get('Titulo', '') + ' '\n",
        "                 + qry_dict.get('Autor', '') + ' '\n",
        "                 + qry_dict.get('Referencia', '') + ' '\n",
        "                 + qry_dict.get('Texto', ''))\n",
        "    qrys_input[qry_id] = qry_input.strip()"
      ],
      "metadata": {
        "id": "KKFdtwSDQMNs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Processa as buscas, retornando os 10 documentos mais relevantes\n",
        "\n",
        "qrys_return = executa_buscas(docs_dict=docs_input,\n",
        "                             qrys_dict=qrys_input,\n",
        "                             qtd_returns=10,\n",
        "                             imprime_log=False)"
      ],
      "metadata": {
        "id": "ni6MX7VLQMIp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificação do resultado de uma busca"
      ],
      "metadata": {
        "id": "UvjU39lNvNiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostra os outputs intermediários da busca para a query 1, como teste\n",
        "\n",
        "qrys_input_teste = {}\n",
        "qrys_input_teste[1] = qrys_input[1]\n",
        "\n",
        "qrys_return_teste = executa_buscas(docs_dict=docs_input,\n",
        "                                   qrys_dict=qrys_input_teste,\n",
        "                                   qtd_returns=10,\n",
        "                                   imprime_log=True)\n",
        "\n",
        "qrys_return_teste"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-JypIbnvRxi",
        "outputId": "31d545a7-a7b4-4aea-a92c-f2ddd7a60995"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processando Query 1\n",
            "\n",
            "Doc ID: 429\n",
            "Score: 25.3735\n",
            "Text: The Information Content of Titles in Engineering Literature Bottle, Robert T.  Since many alerting and information services rely very heavily on the use of titles to transfer information to the potential user, it is essential that  he be aware of the proportion of the information contained in the complete document which will not be deducible from the title and which he will therefore miss.. Methods will be discussed for analyzing the relative information content of the titles of engineering paper and results presented for the amount and  type of information lost through scanning title listing only..    Between one-third and one-half of indexable terms are not retrievable from article titles even if all possible synonyms and  related terms are used.. If all synonyms are used instead of one keyword the amount of information  retrieved is increased by about 70 percent.. The problems of dealing with synonyms and with syntactical variants in searching titles indexes are  discussed.. The possibility of using keywords in journal titles as  supplementary retrieval tags is suggested since they were deemed useful in nearly one-third of the sample of papers analyzed..\n",
            "--------------------------------------------------\n",
            "Doc ID: 722\n",
            "Score: 22.8617\n",
            "Text: Information Transfer Limitations of Titles of Chemical Documents Bottle, R.R. Seeley, C.R.  Some methods of estimating the minimum amounts of information in a document not retrievable through its title are discussed.  An analysis of the information transferred by different types of keywords is helpful in planning search strategies, e.g., 30% of chemical substances mentioned in journal articles are not discernable in their titles even when broad class names are used as synonyms.  Patents have considerably less informative titles than journal articles.  In nuclear science, report titles are also less informative than  those of journal articles, but the proportion of reports with completely  uninformative titles is now only 10% of the 1957 value.  Titles in chemistry are more informative than those in most other fields, but the use of alerting and other services based on titles requires a good understanding of the underlying information transfer principles.\n",
            "--------------------------------------------------\n",
            "Doc ID: 1299\n",
            "Score: 22.5122\n",
            "Text: Current Physics Information Koch, H. William  A new concept in science communication will be given its first test in calendar year 1972.. Primary and secondary contents of a selected subset of  the world's journal literature in physics will be provided in a variety of output formats.. Among them are a monthly microfilm containing the full texts of all articles in the set of journals (Current Physics Microform); an advance abstracts journal describing the articles (Current Physics Advance Abstracts); a printed, classified index of the titles of the articles (Current Physics  Titles); and a computer tape index to the articles (Searchable Physics  Information Notices)..\n",
            "--------------------------------------------------\n",
            "Doc ID: 759\n",
            "Score: 21.6149\n",
            "Text: A New Look at Reference Scattering Cole, P.F.  It was first observed by Bradford that, for a large collection of journal references on a given subject, most of the articles are derived from a small proportion of the total titles.  Bradford listed the journals concerned in order of decreasing productivity and, by plotting the logarithms of the cumulative totals of titles against the cumulative totals of relevant articles produced, he obtained a straight line.  (Similar results have been obtained by many later workers.  The pattern is illustrated by Table I which shows the distribution of references among journal titles obtained by the author during a study of literature usage in the petroleum industry.)  On the basis of these results Bradford then formulated a simple mathematical model to describe reference scattering.  Vickery later pointed out that this 'law of scattering' predicted not a straight line but a curve.  Kendall has now provided a more refined statistical explanation of the straight line observed by Bradford.\n",
            "--------------------------------------------------\n",
            "Doc ID: 65\n",
            "Score: 21.3427\n",
            "Text: A Study of Searching the Eye Research Literature Miller, Russell R.  The paper is a report of most of the major findings of a study in searching the periodical eye research literature.. Questions were collected from eye  researchers and a selected group of these were searched in nine different  secondary sources.. Articles thought to be relevant were Xeroxed and sent to  the eye researchers who subsequently rated the articles.. Articles of eye research interest are found in a wide variety of journals, but a small number of journals carry a large proportion of the articles judged valuable by the eye researchers.. Approximately a fourth of eye research articles are in foreign  languages.. Translations are not readily available.. Despite a delay of more  than 15 month between the original appearance of article in journals and the  mailing of photocopies, about half of the articles of interest to the  researchers were not known to them previously.. For extensive retrospective searches more than one secondary service must be used.. Index Medicus and  Excerpta Medica (Section 12) or Ophthalmic Literature would be good sources.. MEDLARS demand searches were not shown to be clearly superior to manual  searches of Index Medicus.. Titles, abstracts, and full text were shown to be equally effective in permitting searches to retrieve references that were subsequently rated as relevant by the researchers.. A searcher with a background in ophthalmology was able to retrieve more articles of research interest than  other non-ophthalmologist searchers..\n",
            "--------------------------------------------------\n",
            "Doc ID: 928\n",
            "Score: 19.2183\n",
            "Text: The Divided Catalog Elrod, J.M.  As early as 1905 the divided catalog was being presented as a preferable  alternative to the dictionary catalog. Writing in 1958 Dorothy Grosser found that the steady stream of papers on the subject began in 1938.  She reported 21 articles based on actual experience with the divided catalog.  A quick check of her list discloses that all divided catalogs are not represented by articles.  She recorded nine opponents of the divided  catalog and six better known  members of the profession reserving judgement.  Lyle in his new edition of The  Administration of the College Library considers it \"safer,\" rather than \"wiser\"  as in his earlier edition, to await further evidence. Faced at Central  Methodist College Library with a dictionary catalog which had outgrown its  cabinets and which was to be expanded, a survey of catalog user opinion was undertaken to determine if some division of the catalog should be  considered. Some revision of the filing would be needed anyway because of  inconsistencies which had crept in, largely involving the inter-filing of subject and title entries.  The following questions were asked of all users  of the catalog during hours selected at random over several weeks:  1. Are you looking for a particular book or for books on a particular subject?     Were you looking under author, title, or subject?  2. What is your greatest difficulty in using the catalog?  3. How would you feel about having the subject cards in a separate file?   One hundred persons, approximately one tenth of the campus population, were  questioned; 93 per cent felt that they would prefer having subject cards in a  separate catalog, 5 per  cent were opposed, and 2 per cent undecided. It must  be admitted that the prejudice of the person asking may have influenced the  way in which the question was answered - a similar survey made in 1954 by the  University of Toronto showed general support for the dictionary catalog.\n",
            "--------------------------------------------------\n",
            "Doc ID: 820\n",
            "Score: 19.0893\n",
            "Text: Studies to Compare Retrieval Using Titles with that Using Index Terms. SDI from 'Nuclear Science Abstracts' Olive, G.  A Selective dissemination of Information service based on computer scanning of Nuclear Science Abstracts tapes has operated at Harwell since October 1968.. Users' interest profiles are constructed using Euratom index terms and NSA  subject categories assigned to each item in NSA..    The performance of the mechanized SDI service has been compared with that of the pre-existing current awareness service which is based on visual scanning of journals and reports by information staff.. The visual service was found to be providing an important service of good currency and high precision, about 85%,  to a limited number of users.. the mechanized service is less selective and of  lower precision, approximately 50%, but can be expanded more readily..    In order to compare the effectiveness of Euratom index terms and words on  titles for computer SDI matching, an experiment was set up in which sixty  users of the mechanized service assessed NSA document notifications which were  generated by matching either index terms and subject categories, or words in  titles and subject categories, without being aware of the method of matching..  Over 10,000 document assessments, fron six issues of NSA were returned.. The  average precision was 45.6% for index terms and 47.3% for title words.. Index  terms retrieved more documents, in the ratio 1.13:1, but both systems missed  many relevant documents retrieved by the other.. Index terms retrieved only 58%  of the relevant documents selected by titles.. The converse ratio was 51%..    No significant effects of document types or subject on the relative  effectiveness of two matching systems were found, but when the results were  analyzed by title length it appeared that for titles longer than about 100  characters title words gave recall equal to that of index terms, though with a  lower precision..    A detailed study of samples of items found by visual scanning but missed by  computer matching or found by one computer method but not by the other, was made to identify reasons for failure..\n",
            "--------------------------------------------------\n",
            "Doc ID: 603\n",
            "Score: 18.5460\n",
            "Text: The Efficiency of MEDLARS Titles for Retrieval Miller, William L.  Previous research has indicated that the titles rather than index terms  would, in the standard MEDLARS system, gave lower Recall but higher Precision.. A title searching technique is described which allows the number of references retrieved to be fixed before a search commences.. With this technique the greater applicability of title-terms offsets their relative paucity.. The title-searching technique is tested using queries put to MEDLARS.. These  queries were not specially solicited for the test.. Title searching is compared with the standard MEDLARS index term search and with an index term search with  fixed output size.. For equal output sizes, Title searching retrieves 4  relevant references for every 5 retrieved by index term searching.. Thus the  relative retrieval efficiency of Title and Index terms is so close that the  choice of one method or the other must be primarily on economic grounds..\n",
            "--------------------------------------------------\n",
            "Doc ID: 1055\n",
            "Score: 18.4904\n",
            "Text: The Use of Biomedical Periodical Literature at the National Lending Library for Science and Technology Wood, D.N. Bower, C.A.  The paper reports the results of a two week questionnaire survey of the use of biomedical periodical literature carried out at the UK National Lending  Library in February 1969.  The survey was designated to discover the subject, date and language characteristics of the borrowed literature, the most frequently requested journals, and the most popular sources of references to biomedical publications.   The loans were spread over 1,084 titles, although 9 per cent of the issues involved only 2 per cent of the titles.  The literature in most demand was less than one year old and in the case of medicine 50 per cent of the requests were for literature lss than 3 1/2 years old.  The half-life for the biological literature was somewhat longer at 5 3/4 years.  The majority of issues (87.8 per cent) involved English language periodicals.   Overall, the principal sources of references to the requested literature were citation lists in other periodical articles.  Regarding the more recent literature, however, abstracting and indexing journals were the primary sources of information.  For medical references Index Medicus was the most used indexing publication, and for biological references Current Contents.\n",
            "--------------------------------------------------\n",
            "Doc ID: 76\n",
            "Score: 18.4718\n",
            "Text: Biomedical Literature: Analysis of Journal Articles    Collected by a Radiation- and Cell-Biologist Leith, John D. Jr.  The author's journal reference cards for 1965 and 1966 were analyzed  according to three \"interest patterns\": (I) the total collection of 1469  article titles, a \"potentially useful\" set; (II) a subset concerning only his research speciality; and (III) a subset of articles defined as \"useful\". For each pattern, journals were ranked by frequency of use and a scatter diagram  was drawn..    Patterns I and II largely resembled patterns obtained by counting citations in basic journals or by counting publications of selected researchers.. Pattern\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: [429, 722, 1299, 759, 65, 928, 820, 603, 1055, 76]}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparação dos resultados com a prova real"
      ],
      "metadata": {
        "id": "nK9OYBsacEjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcula a métrica de precisão para cada query\n",
        "\n",
        "precisao_por_qry = {}\n",
        "for qry_id, return_list in qrys_return.items():\n",
        "\n",
        "    tp = 0          # Verdadeiros positivos\n",
        "    fp = 0          # Falsos positivos\n",
        "\n",
        "    if qry_id not in rels_dict:\n",
        "        precisao_por_qry[qry_id] = 0\n",
        "        continue\n",
        "\n",
        "    for doc_id in return_list:\n",
        "        if str(doc_id) in rels_dict[qry_id]['Doc IDs']:\n",
        "            tp += 1\n",
        "        else:\n",
        "            fp += 1\n",
        "\n",
        "    precisao_por_qry[qry_id] = tp/(tp + fp)"
      ],
      "metadata": {
        "id": "KWQLyHzaQMGH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcula a precisão média entre todas as queries\n",
        "\n",
        "precisao_media = sum(precisao_por_qry.values())/len(precisao_por_qry)\n",
        "\n",
        "precisao_media"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGlWZhDGwsrp",
        "outputId": "f1e2aa94-5ace-426b-8f59-ea4b366052ab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23660714285714293"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}